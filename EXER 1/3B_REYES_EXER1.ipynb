{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Laboratory Exercise 1: Propositional Logic in Python**\n",
        "\n",
        "\n",
        "### Name: Vanesse V. Reyes\n",
        "### Section: BSCS - 3BIS\n",
        "### Course: CCST 101 | Advance Presentation Reasoning\n",
        "### Topic 1.2: Logic Based Presentation\n"
      ],
      "metadata": {
        "id": "yuOaRwoy6Km4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Exercise #1 Solution:**\n",
        "# Define propositions\n",
        "#@markdown # **Is it:**\n",
        "raining = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Function to determine if the ground is wet based on rain\n",
        "def is_ground_wet(raining):\n",
        "    return raining  # If it's raining, the ground is wet\n",
        "\n",
        "# Function to determine if the match will light based on the ground's state\n",
        "def can_match_light(ground_is_wet):\n",
        "    return not ground_is_wet  # The match lights only if the ground is not wet\n",
        "\n",
        "# Main logic to simulate the conditions\n",
        "ground_is_wet = is_ground_wet(raining)\n",
        "match_lights = can_match_light(ground_is_wet)\n",
        "\n",
        "if match_lights:\n",
        "    print(\"The match will light.\")\n",
        "else:\n",
        "    print(\"The match will not light.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDNqtfw86a7f",
        "outputId": "b463493f-92a5-49b9-fcc6-281797471edd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The match will not light.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Exercise #2 Solution:**\n",
        "\n",
        "person = \"Socrates\" #@param {type:\"string\"}\n",
        "\n",
        "def is_human(person):\n",
        "    return person == \"Socrates\"  # Returns True if the person is Socrates\n",
        "\n",
        "def is_mortal(person):\n",
        "    return is_human(person)  # A human is considered mortal\n",
        "\n",
        "# Check if the person is mortal and print the result\n",
        "if is_mortal(person):\n",
        "    print(f\"{person} is a mortal.\")\n",
        "else:\n",
        "    print(f\"{person} is not a mortal.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw8cxlvY6hRr",
        "outputId": "d548aa64-2ae0-4605-fed9-01c16298480b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Socrates is a mortal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Exercise #3 Solution**\n",
        "\n",
        "# Function to perform modus ponens\n",
        "def modus_ponens(rules, facts):\n",
        "    conclusions = []  # Initialize an empty list to store conclusions\n",
        "    for rule in rules:\n",
        "        premise, conclusion = rule\n",
        "        if premise in facts:  # Check if the premise is in the facts\n",
        "            conclusions.append(conclusion)  # Add conclusion if the premise is found\n",
        "    return conclusions\n",
        "\n",
        "#@markdown # **Rules and Facts:**\n",
        "\n",
        "# Input for rules and facts\n",
        "rules_input = \"Dog,Cat\"  #@param {type:\"string\", default:\"X,Y\"}\n",
        "facts_input = \"Dog\"  #@param {type:\"string\", default:\"X\"}\n",
        "\n",
        "# Parse the rules input\n",
        "rules = [tuple(rule.split(',')) for rule in rules_input.split(';')]\n",
        "\n",
        "# Parse the facts input\n",
        "facts = facts_input.split(',')\n",
        "\n",
        "# Get the inferred conclusions\n",
        "conclusions = modus_ponens(rules, facts)\n",
        "print(\"Inferred Conclusions: \", conclusions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tqe1YGO6lnZ",
        "outputId": "fdb84b07-4769-4340-ab62-aca115050a60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred Conclusions:  ['Cat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title **Exercise #4 Solution:**\n",
        "\n",
        "# Define the initial state\n",
        "john_is_hungry = True  #@param {type:\"boolean\"}\n",
        "\n",
        "# Function to determine if John has eaten\n",
        "def has_eaten(john_is_hungry):\n",
        "    return not john_is_hungry  # John has eaten if he is not hungry\n",
        "\n",
        "# Determine John's current state based on his hunger\n",
        "if john_is_hungry:\n",
        "    # John is hungry, so he hasn't eaten\n",
        "    print(\"John is hungry and has not eaten yet.\")\n",
        "else:\n",
        "    # John is not hungry, so he has eaten\n",
        "    print(\"John has already eaten and is no longer hungry.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11wUtGEF6pl0",
        "outputId": "dd15a526-cc06-4c6d-8a4e-34058a488aac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John is hungry and has not eaten yet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install NLTK and download necessary resources\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import random\n",
        "\n",
        "# Initialize sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define response categories and their corresponding phrases\n",
        "responses = {\n",
        "    \"greeting\": [\"Hello! How can I assist you today?\", \"Hi there! What can I do for you?\", \"Hey! How's it going?\"],\n",
        "    \"farewell\": [\"Goodbye! Have a great day!\", \"See you later! Take care!\", \"Farewell! Until next time!\"],\n",
        "    \"thank_you\": [\"You're welcome!\", \"Glad I could help!\", \"No problem!\"],\n",
        "    \"complaint\": [\"I'm sorry to hear that. Can you provide more details?\", \"I apologize for the inconvenience. How can I assist you further?\"],\n",
        "    \"positive_feedback\": [\"Thank you for the positive feedback!\", \"I'm glad to hear you're satisfied!\", \"Great to hear you're happy with the service!\"],\n",
        "    \"negative_feedback\": [\"I'm sorry to hear that you're not satisfied. How can we improve?\", \"Your feedback is important. Can you tell us more about what went wrong?\"],\n",
        "    \"neutral\": [\"I see. Is there anything else you would like to discuss?\", \"Thank you for your input. How can I help you further?\"]\n",
        "}\n",
        "\n",
        "# Define keywords for classification\n",
        "keywords = {\n",
        "    \"greeting\": [\"hello\", \"hi\", \"hey\", \"greetings\", \"salutations\"],\n",
        "    \"farewell\": [\"goodbye\", \"see you later\", \"farewell\", \"take care\"],\n",
        "    \"thank_you\": [\"thank you\", \"thanks\", \"much appreciated\"],\n",
        "    \"complaint\": [\"not happy\", \"disappointing\", \"complaint\"]\n",
        "}\n",
        "\n",
        "def classify_statement(statement):\n",
        "    \"\"\"Classify the type of statement based on keywords and sentiment analysis.\"\"\"\n",
        "    lower_statement = statement.lower()\n",
        "\n",
        "    for category, words in keywords.items():\n",
        "        if any(word in lower_statement for word in words):\n",
        "            return category\n",
        "\n",
        "    sentiment = sia.polarity_scores(statement)['compound']\n",
        "    if sentiment >= 0.05:\n",
        "        return \"positive_feedback\"\n",
        "    elif sentiment <= -0.05:\n",
        "        return \"negative_feedback\"\n",
        "\n",
        "    return \"neutral\"\n",
        "\n",
        "def generate_response(statement_type):\n",
        "    \"\"\"Generate a random response based on the classified statement type.\"\"\"\n",
        "    return random.choice(responses.get(statement_type, responses[\"neutral\"]))\n",
        "\n",
        "# Input from the user\n",
        "user_input = input(\"Please enter your statement: \")  # Allow user input\n",
        "\n",
        "# Classify the user's statement and generate a response\n",
        "statement_type = classify_statement(user_input)\n",
        "response = generate_response(statement_type)\n",
        "\n",
        "print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-reeOxJ64k-",
        "outputId": "815b10a0-18ae-456f-ee73-39a9e592ebbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report: **Logic-Based Chatbot Implementation**\n",
        "\n",
        "## Introduction\n",
        "This report outlines the development and functionality of a logic-based chatbot designed to classify user statements and generate appropriate responses. The chatbot utilizes the Natural Language Toolkit (NLTK) for sentiment analysis and employs a structured approach to categorize inputs based on predefined keywords and sentiment scores.\n",
        "\n",
        "## System Overview\n",
        "The chatbot operates through a series of components that work together to process user input, classify it, and deliver relevant responses. The primary elements include:\n",
        "\n",
        "- **Library Utilization**: The chatbot leverages NLTK for natural language processing, specifically using the VADER sentiment analysis tool to assess the emotional tone of user statements.\n",
        "- **Response Categorization**: Responses are organized into distinct categories, such as greetings, farewells, thank yous, complaints, and feedback types (positive, negative, neutral). This categorization allows for tailored responses that align with user intent.\n",
        "- **Keyword Matching**: A set of keywords is defined for each response category. The chatbot analyzes user input to identify keywords that match these categories, facilitating accurate classification.\n",
        "\n",
        "## Functionality Breakdown\n",
        "- **Input Processing**: The chatbot prompts users for input, allowing real-time interaction. User statements are then processed to determine their classification.\n",
        "- **Classification Logic**:\n",
        "  - The system first checks for keyword matches within the user's statement to identify its category.\n",
        "  - If no keywords are found, sentiment analysis is performed to evaluate the emotional tone of the statement. Based on the sentiment score, the input is classified as positive, negative, or neutral.\n",
        "- **Response Generation**: Once classified, the chatbot selects a random response from the corresponding category. This randomness adds variability to interactions, making conversations feel more natural.\n",
        "\n",
        "## User Interaction\n",
        "The chatbot's design emphasizes user engagement through dynamic interaction. By allowing users to input their statements freely, it fosters a more conversational experience compared to static responses. This adaptability enhances user satisfaction and encourages ongoing dialogue.\n",
        "\n",
        "## Conclusion\n",
        "The logic-based chatbot effectively combines keyword matching with sentiment analysis to create an engaging conversational agent. Its structured approach allows for easy management and expansion of response categories and keywords. Future enhancements could include integrating more sophisticated natural language processing techniques or expanding the database of keywords and responses to cover a broader range of topics.\n",
        "\n",
        "Overall, this implementation serves as a foundational model for developing more advanced chatbots capable of handling complex interactions in various applications such as customer service, education, and personal assistance."
      ],
      "metadata": {
        "id": "_P7FnAls7jOQ"
      }
    }
  ]
}